{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_train = pd.read_csv('D:/train_fix.csv')\n",
    "Y_train = pd.read_csv('D:/train_label.csv')\n",
    "X_test = pd.read_csv('D:/test.csv')\n",
    "Y_test = pd.read_csv('D:/test_nolabel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>...</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>agent</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.305161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>7/1/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.052227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>7/3/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>74.546401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>7/3/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>76.376288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>7/3/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>49.411647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>7/3/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91525</th>\n",
       "      <td>91526</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2017</td>\n",
       "      <td>March</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>79.223571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>3/22/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91526</th>\n",
       "      <td>91527</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>March</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.822102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>4/2/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91527</th>\n",
       "      <td>91528</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>March</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>90.814554</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>4/1/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91528</th>\n",
       "      <td>91529</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>March</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>38.135565</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>4/10/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91529</th>\n",
       "      <td>91530</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>March</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>58.196470</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>4/1/2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91530 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID         hotel  is_canceled  lead_time  arrival_date_year  \\\n",
       "0          0  Resort Hotel            0        342               2015   \n",
       "1          1    City Hotel            0        257               2015   \n",
       "2          2    City Hotel            0        257               2015   \n",
       "3          3    City Hotel            0        257               2015   \n",
       "4          4    City Hotel            0        257               2015   \n",
       "...      ...           ...          ...        ...                ...   \n",
       "91525  91526  Resort Hotel            1         19               2017   \n",
       "91526  91527  Resort Hotel            0         28               2017   \n",
       "91527  91528  Resort Hotel            0          2               2017   \n",
       "91528  91529  Resort Hotel            0         30               2017   \n",
       "91529  91530  Resort Hotel            0          1               2017   \n",
       "\n",
       "      arrival_date_month  arrival_date_week_number  arrival_date_day_of_month  \\\n",
       "0                   July                        27                          1   \n",
       "1                   July                        27                          1   \n",
       "2                   July                        27                          1   \n",
       "3                   July                        27                          1   \n",
       "4                   July                        27                          1   \n",
       "...                  ...                       ...                        ...   \n",
       "91525              March                        13                         31   \n",
       "91526              March                        13                         31   \n",
       "91527              March                        13                         31   \n",
       "91528              March                        13                         31   \n",
       "91529              March                        13                         31   \n",
       "\n",
       "       stays_in_weekend_nights  stays_in_week_nights  ...  deposit_type  \\\n",
       "0                            0                     0  ...    No Deposit   \n",
       "1                            0                     2  ...    No Deposit   \n",
       "2                            0                     2  ...    No Deposit   \n",
       "3                            0                     2  ...    No Deposit   \n",
       "4                            0                     2  ...    No Deposit   \n",
       "...                        ...                   ...  ...           ...   \n",
       "91525                        0                     2  ...    No Deposit   \n",
       "91526                        0                     2  ...    No Deposit   \n",
       "91527                        0                     1  ...    No Deposit   \n",
       "91528                        3                     7  ...    No Deposit   \n",
       "91529                        0                     1  ...    No Deposit   \n",
       "\n",
       "       agent  company days_in_waiting_list customer_type        adr  \\\n",
       "0        NaN      NaN                    0     Transient  -6.305161   \n",
       "1        6.0      NaN                    0     Transient  75.052227   \n",
       "2        6.0      NaN                    0     Transient  74.546401   \n",
       "3        6.0      NaN                    0     Transient  76.376288   \n",
       "4        6.0      NaN                    0     Transient  49.411647   \n",
       "...      ...      ...                  ...           ...        ...   \n",
       "91525  250.0      NaN                    0     Transient  79.223571   \n",
       "91526    NaN      NaN                    0     Transient  -6.822102   \n",
       "91527    NaN      NaN                    0     Transient  90.814554   \n",
       "91528  250.0      NaN                    0     Transient  38.135565   \n",
       "91529  250.0      NaN                    0     Transient  58.196470   \n",
       "\n",
       "      required_car_parking_spaces  total_of_special_requests  \\\n",
       "0                               0                          0   \n",
       "1                               0                          0   \n",
       "2                               0                          0   \n",
       "3                               0                          0   \n",
       "4                               0                          0   \n",
       "...                           ...                        ...   \n",
       "91525                           0                          1   \n",
       "91526                           0                          0   \n",
       "91527                           0                          2   \n",
       "91528                           0                          1   \n",
       "91529                           0                          1   \n",
       "\n",
       "       reservation_status  reservation_status_date  \n",
       "0               Check-Out                 7/1/2015  \n",
       "1               Check-Out                 7/3/2015  \n",
       "2               Check-Out                 7/3/2015  \n",
       "3               Check-Out                 7/3/2015  \n",
       "4               Check-Out                 7/3/2015  \n",
       "...                   ...                      ...  \n",
       "91525            Canceled                3/22/2017  \n",
       "91526           Check-Out                 4/2/2017  \n",
       "91527           Check-Out                 4/1/2017  \n",
       "91528           Check-Out                4/10/2017  \n",
       "91529           Check-Out                 4/1/2017  \n",
       "\n",
       "[91530 rows x 33 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "91525    0\n",
       "91526    0\n",
       "91527    0\n",
       "91528    0\n",
       "91529    0\n",
       "Name: hotel_City Hotel, Length: 91530, dtype: uint8"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cdf['hotel_City Hotel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.07250002731315"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train['country']=='PRT').dot([1 for i in range(91531)])/91531 *100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing for is_canceled prediction\n",
    "def data_process_cancel(X):\n",
    "    \n",
    "    # drop the columns only in train data\n",
    "    only_inTrain = ['reservation_status', 'reservation_status_date']\n",
    "    X = X.loc[:, ~X.columns.isin(only_inTrain)].copy() \n",
    "    \n",
    "    # drop the columns not related to is_canceled\n",
    "    not_related = ['ID', 'days_in_waiting_list', 'required_car_parking_spaces',\n",
    "                  'reserved_room_type', 'assigned_room_type']\n",
    "    X = X.loc[:, ~X.columns.isin(not_related)]\n",
    "    \n",
    "    # missing data\n",
    "    X['children'] = X['children'].fillna(0)\n",
    "    X['country'] = X['country'].fillna(X['country'].value_counts().iloc[0]) # fill in the max\n",
    "    X['company'] = (X['company'].notnull()).astype('int') # replace all non-NaN entries of a dataframe with 1 and all NaN with 0\n",
    "    \n",
    "    kagent = list(X_train['agent'].value_counts().iloc[:20].index)\n",
    "    X['agent'] = np.where(X['agent'].isin(kagent), X['agent'], 0)\n",
    "    X['agent'] = X['agent'].fillna(0)\n",
    "    \n",
    "    # combine\n",
    "    X['child'] = X['children'] + X['babies']\n",
    "    X = X.drop(['children', 'babies'], axis=1)\n",
    "    \n",
    "    # add new column\n",
    "    X['previous_cancel_rate'] =  X['previous_cancellations']/(X['previous_cancellations']+X['previous_bookings_not_canceled'])\n",
    "    X['previous_cancel_rate'] = X['previous_cancel_rate'].fillna(0)\n",
    "    X = X.drop(['previous_cancellations', 'previous_bookings_not_canceled'], axis=1)  \n",
    "    \n",
    "    # threshold\n",
    "    X['lead_time'] = np.where(X['lead_time']>400, 1, 0)\n",
    "    \n",
    "    # get dummy\n",
    "    dummy_cols = ['hotel', 'arrival_date_year', 'arrival_date_month', 'arrival_date_week_number',\n",
    "       'arrival_date_day_of_month', 'meal', 'country', 'market_segment', 'distribution_channel',\n",
    "       'deposit_type', 'company', 'customer_type', 'agent']\n",
    "    X = pd.get_dummies(X, columns=dummy_cols)\n",
    "    return X\n",
    "\n",
    "X_train_cdf = data_process_cancel(X_train.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "def test_process_cancel(X):\n",
    "    \n",
    "    # drop the columns not related to is_canceled\n",
    "    not_related = ['ID', 'days_in_waiting_list', 'required_car_parking_spaces',\n",
    "                  'reserved_room_type', 'assigned_room_type']\n",
    "    X = X.loc[:, ~X.columns.isin(not_related)]\n",
    "    \n",
    "    # missing data\n",
    "    X['country'] = X['country'].fillna(X['country'].value_counts().iloc[0]) # fill in the max\n",
    "    X['company'] = (X['company'].notnull()).astype('int') # replace all non-NaN entries of a dataframe with 1 and all NaN with 0\n",
    "    \n",
    "    kagent = list(X_train['agent'].value_counts().iloc[:20].index)\n",
    "    X['agent'] = np.where(X['agent'].isin(kagent), X['agent'], 0)\n",
    "    X['agent'] = X['agent'].fillna(0)\n",
    "    \n",
    "    # combine\n",
    "    X['child'] = X['children'] + X['babies']\n",
    "    X = X.drop(['children', 'babies'], axis=1)\n",
    "    \n",
    "    # add new column\n",
    "    X['previous_cancel_rate'] =  X['previous_cancellations']/(X['previous_cancellations']+X['previous_bookings_not_canceled'])\n",
    "    X['previous_cancel_rate'] = X['previous_cancel_rate'].fillna(0)\n",
    "    X = X.drop(['previous_cancellations', 'previous_bookings_not_canceled'], axis=1)  \n",
    "    \n",
    "    # threshold\n",
    "    X['lead_time'] = np.where(X['lead_time']>400, 1, 0)\n",
    "    \n",
    "    # get dummy\n",
    "    dummy_cols = ['hotel', 'arrival_date_year', 'arrival_date_month', 'arrival_date_week_number',\n",
    "       'arrival_date_day_of_month', 'meal', 'country', 'market_segment', 'distribution_channel',\n",
    "       'deposit_type', 'company', 'customer_type', 'agent']\n",
    "    X = pd.get_dummies(X, columns=dummy_cols)\n",
    "    \n",
    "\n",
    "    T = X_train_cdf.columns.tolist()\n",
    "    Mi = [i for i in X_train_cdf if i not in X]\n",
    "    for i in Mi:\n",
    "        X[i] = 0\n",
    "\n",
    "    X=X[X_train_cdf.columns.tolist()]    \n",
    "    \n",
    "    \n",
    "    return X\n",
    "\n",
    "X_test_cdf = test_process_cancel(X_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "X_train_c = X_train_cdf.to_numpy()\n",
    "Y_train_c = X_train['is_canceled'].copy().to_numpy()\n",
    "\n",
    "# test data\n",
    "X_test_c = X_test_cdf.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data\n",
    "X_train_c = X_train_cdf.loc[:, ~X_train_cdf.columns.isin(['is_canceled','adr'])].to_numpy()\n",
    "Y_train_Cancel = X_train_cdf['is_canceled'].copy().to_numpy()\n",
    "Y_train_ADR = X_train_cdf['adr'].copy().to_numpy()\n",
    "\n",
    "# Shuffle data for train\n",
    "Train_copy = X_train_cdf.sample(frac=1, random_state=1) # shuffle\n",
    "\n",
    "Tra_ADR = Train_copy['adr']\n",
    "Tra_X = Train_copy.drop(['is_canceled','adr'], axis=1)\n",
    "Tra_Y = Train_copy['is_canceled']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 folds cv\n",
    "Tra_5folds_ADR = [Tra_ADR[18306:],Tra_ADR[0:18306].append(Tra_ADR[36612:]),Tra_ADR[0:36612].append(Tra_ADR[54918:]),\n",
    "                  Tra_ADR[0:54918].append(Tra_ADR[73224:]),Tra_ADR[0:73224]]\n",
    "Tra_5folds_X = [Tra_X.iloc[18306:],Tra_X.iloc[0:18306].append(Tra_X.iloc[36612:]),Tra_X.iloc[0:36612].append(Tra_X.iloc[54918:]),\n",
    "                  Tra_X.iloc[0:54918].append(Tra_X.iloc[73224:]),Tra_X.iloc[0:73224]]\n",
    "Tra_5folds_Y = [Tra_Y[18306:],Tra_Y[0:18306].append(Tra_Y[36612:]),Tra_Y[0:36612].append(Tra_Y[54918:]),\n",
    "                  Tra_Y[0:54918].append(Tra_Y[73224:]),Tra_Y[0:73224]]\n",
    "\n",
    "Val_5folds_X = [Tra_X.iloc[0:18306],Tra_X.iloc[18306:36612],Tra_X.iloc[36612:54918],Tra_X.iloc[54918:73224],Tra_X.iloc[73224:]]\n",
    "Val_5folds_ADR = [Tra_ADR[0:18306],Tra_ADR[18306:36612],Tra_ADR[36612:54918],Tra_ADR[54918:73224],Tra_ADR[73224:]]\n",
    "Val_5folds_Y = [Tra_Y[0:18306],Tra_Y[18306:36612],Tra_Y[36612:54918],Tra_Y[54918:73224],Tra_Y[73224:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict is_canceled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic reg with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "Accuracy = []\n",
    "regularization = [0.001, 0.01, 0.05, 0.25, 0.5, 1, 10, 100, 1000]\n",
    "for c in regularization:\n",
    "    E_val_acc = []\n",
    "    for i in range(5):\n",
    "        lr = LogisticRegression(C=c)\n",
    "        lr.fit(Tra_5folds_X[i] , Tra_5folds_Y[i] )\n",
    "        E_val_acc.append(accuracy_score(Val_5folds_Y[i], lr.predict(Val_5folds_X[i])))\n",
    "    Accuracy.append(np.mean(E_val_acc))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest C: 10\n",
      "E_val_accuracy: 0.8228777450016389\n",
      "Train Acc: 0.8244400742925817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "highestC = [regularization[i] for i in range(len(regularization)) if Accuracy[i] == max(Accuracy)][0]\n",
    "print('highest C:',highestC)\n",
    "print('E_val_accuracy:',max(Accuracy))\n",
    "\n",
    "final_model = LogisticRegression(C = highestC)\n",
    "final_model.fit(X_train_c, Y_train_Cancel)\n",
    "print(f'Train Acc: {accuracy_score(Y_train_Cancel, final_model.predict(X_train_c))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = final_model.predict(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data = pd.read_csv(\"D:/test.csv\")\n",
    "Cancel_label =  pd.DataFrame() \n",
    "Cancel_label['arrival_date'] = Test_data['ID']\n",
    "Cancel_label['logistic'] = y_pred_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion: gini\n",
      "E_val_acc for j=1: 0.8238391784114498\n",
      "E_val_acc for j=2: 0.8238391784114498\n",
      "E_val_acc for j=3: 0.8238391784114498\n",
      "E_val_acc for j=4: 0.8238391784114498\n",
      "E_val_acc for j=5: 0.8238391784114498\n",
      "E_val_acc for j=6: 0.8238391784114498\n",
      "E_val_acc for j=7: 0.8238391784114498\n",
      "E_val_acc for j=8: 0.8238391784114498\n",
      "E_val_acc for j=9: 0.8238391784114498\n",
      "E_val_acc for j=10: 0.8238391784114498\n",
      "E_val_acc for j=11: 0.8238391784114498\n",
      "E_val_acc for j=12: 0.8238391784114498\n",
      "E_val_acc for j=13: 0.8238391784114498\n",
      "E_val_acc for j=14: 0.8238391784114498\n",
      "E_val_acc for j=15: 0.8238391784114498\n",
      "Criterion: entropy\n",
      "E_val_acc for j=1: 0.8238391784114498\n",
      "E_val_acc for j=2: 0.8238391784114498\n",
      "E_val_acc for j=3: 0.8238391784114498\n",
      "E_val_acc for j=4: 0.8238391784114498\n",
      "E_val_acc for j=5: 0.8238391784114498\n",
      "E_val_acc for j=6: 0.8238391784114498\n",
      "E_val_acc for j=7: 0.8238391784114498\n",
      "E_val_acc for j=8: 0.8238391784114498\n",
      "E_val_acc for j=9: 0.8238391784114498\n",
      "E_val_acc for j=10: 0.8238391784114498\n",
      "E_val_acc for j=11: 0.8238391784114498\n",
      "E_val_acc for j=12: 0.8238391784114498\n",
      "E_val_acc for j=13: 0.8238391784114498\n",
      "E_val_acc for j=14: 0.8238391784114498\n",
      "E_val_acc for j=15: 0.8238391784114498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "Cri = ['gini','entropy']\n",
    "for c in Cri:\n",
    "    print('Criterion:',c)\n",
    "    for j in range(15):\n",
    "        k=j+1\n",
    "        E_val_acc = []\n",
    "        for i in range(5):\n",
    "            model1=DecisionTreeClassifier(max_depth=k,criterion=c)\n",
    "            model1.fit(Tra_5folds_X[i] , Tra_5folds_Y[i])\n",
    "            E_val_acc.append(accuracy_score(Val_5folds_Y[i], lr.predict(Val_5folds_X[i])))\n",
    "        print(f'E_val_acc for j={k}: {np.mean(E_val_acc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8661531738227903\n"
     ]
    }
   ],
   "source": [
    "final_model = DecisionTreeClassifier(max_depth=12,criterion='entropy')\n",
    "final_model.fit(X_train_c, Y_train_Cancel)\n",
    "print(f'Train Acc: {accuracy_score(Y_train_Cancel, final_model.predict(X_train_c))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = final_model.predict(X_test_c)\n",
    "Cancel_label['decision'] = y_pred_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9838304381077242"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "md1_rf = RandomForestClassifier(max_depth=50, n_estimators=1000,random_state=1)\n",
    "md1_rf.fit(X_train_c, Y_train_Cancel)\n",
    "y_pred = md1_rf.predict(X_train_c)\n",
    "accuracy_score(Y_train_Cancel, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Model Selection by best E_oob_accuracy\n",
    "\n",
    "C = [30,40,50,60,70]\n",
    "E_oob_acc=[]\n",
    "for i in C:\n",
    "    md1_rf = RandomForestClassifier(max_depth=i, n_estimators=1000,oob_score=True,random_state=1,n_jobs=-1)\n",
    "    md1_rf.fit(X_train_c, Y_train_Cancel)\n",
    "    y_pred = md1_rf.predict(X_train_c)\n",
    "    E_oob_acc.append(accuracy_score(Y_train_Cancel, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9384682617720966, 0.9708510870752759, 0.9838304381077242, 0.9860264394187698, 0.9861466185949962]\n"
     ]
    }
   ],
   "source": [
    "print(E_oob_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9861466185949962\n"
     ]
    }
   ],
   "source": [
    "md1_rf = RandomForestClassifier(max_depth=70, n_estimators=1000,random_state=1,n_jobs=-1)\n",
    "md1_rf.fit(X_train_c, Y_train_Cancel)\n",
    "y_pred = md1_rf.predict(X_train_c)\n",
    "print(f'Train Acc: {accuracy_score(Y_train_Cancel, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = md1_rf.predict(X_test_c)\n",
    "Cancel_label['rf'] = y_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cancel_label.to_csv(r'C:\\Users\\USER\\Desktop\\record.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-28cb4c8efadd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mNN_model\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mNN_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTra_5folds_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mTra_5folds_Y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mE_val_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVal_5folds_Y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVal_5folds_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'E_val_acc for layer={j}: {np.mean(E_val_acc)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \"\"\"\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1907\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1909\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1911\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.values_from_object\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         \"\"\"\n\u001b[0;32m   5486\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mas_array\u001b[1;34m(self, transpose, items)\u001b[0m\n\u001b[0;32m    828\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 830\u001b[1;33m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtranspose\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    855\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "activation = ['relu']\n",
    "\n",
    "for a in activation:\n",
    "    print('Activation:',a)\n",
    "    for j in [400,500]:\n",
    "        E_val_acc = []\n",
    "        for i in range(5):\n",
    "            NN_model =  MLPClassifier(random_state=0,hidden_layer_sizes=j,activation=a)\n",
    "            NN_model.fit(Tra_5folds_X[i] , Tra_5folds_Y[i])\n",
    "            E_val_acc.append(accuracy_score(Val_5folds_Y[i], lr.predict(Val_5folds_X[i])))\n",
    "        print(f'E_val_acc for layer={j}: {np.mean(E_val_acc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10716  1030]\n",
      " [ 1344  5216]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8703157434720856"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "NN_model =  MLPClassifier(random_state=0,hidden_layer_sizes=500)\n",
    "NN_model.fit(x_train, y_train)\n",
    "y_pred = NN_model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_pred = NN_model.predict(X_test_c )\n",
    "NN_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[58203   568]\n",
      " [ 1011 31748]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9827488255216869"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use all data\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "NN_model =  MLPClassifier(random_state=0,hidden_layer_sizes=500)\n",
    "NN_model.fit(X_train_c, Y_train_c)\n",
    "y_pred = NN_model.predict(X_train_c)\n",
    "print(confusion_matrix(Y_train_c, y_pred))\n",
    "accuracy_score(Y_train_c, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allNN_pred = NN_model.predict(X_test_c )\n",
    "allNN_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55835  2936]\n",
      " [ 6242 26517]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8997268655085764"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier(max_depth= 10)\n",
    "gb_model.fit(X_train_c, Y_train_Cancel)\n",
    "y_pred = gb_model.predict(X_train_c)\n",
    "print(confusion_matrix(Y_train_Cancel, y_pred))\n",
    "accuracy_score(Y_train_Cancel, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_pred = gb_model.predict(X_test_c )\n",
    "gb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10823   923]\n",
      " [ 2341  4219]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.821697803998689"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "ada.fit(x_train, y_train)\n",
    "y_pred = ada.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_pred = ada.predict(X_test_c )\n",
    "ada_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54129  4642]\n",
      " [11512 21247]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8235114170217415"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use all data\n",
    "ada = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "ada.fit(X_train_c, Y_train_c)\n",
    "y_pred = ada.predict(X_train_c)\n",
    "print(confusion_matrix(Y_train_c, y_pred))\n",
    "accuracy_score(Y_train_c, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allada_pred = ada.predict(X_test_c )\n",
    "allada_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Blending for all classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use incomplete data\n",
    "Blend_C = [(dt_pred[i]+rf_pred[i]+NN_pred[i]+gb_pred[i]+ada_pred[i]+logistic_pred[i])/6 for i in range(len(dt_pred))]\n",
    "for i in range(len(Blend_C)):\n",
    "    if Blend_C[i]>=0.5:\n",
    "        Blend_C[i] = 1\n",
    "    else: Blend_C[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ALL data\n",
    "AllBlend_C = [(alldt_pred[i]+allrf_pred[i]+allNN_pred[i]+allgb_pred[i]+allada_pred[i]+alllogistic_pred[i])/6 for i in range(len(alldt_pred))]\n",
    "for i in range(len(AllBlend_C)):\n",
    "    if AllBlend_C[i]>=0.5:\n",
    "        AllBlend_C[i] = 1\n",
    "    else: AllBlend_C[i]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of ADR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094.3492768788053\n",
      "1096.1857551220705\n",
      "1094.6863630872458\n",
      "1094.302576562821\n",
      "1100.3253535570843\n",
      "[3.0827245159192695e+23, 1.1568795001828866e+23, 2.290983901326358e+23, 7.31119724055254e+22, 2.0814065750867614e+22]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "E_val_mse = []\n",
    "for i in range(5):\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(Tra_5folds_X[i] , Tra_5folds_ADR[i] )\n",
    "    print(mean_squared_error(Tra_5folds_ADR[i], reg.predict(Tra_5folds_X[i])))\n",
    "    E_val_mse.append(mean_squared_error(Val_5folds_ADR[i], reg.predict(Val_5folds_X[i])))\n",
    "print(E_val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of test: 1096.7804313372787\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train_c, Y_train_ADR)\n",
    "y_pred = reg.predict(X_train_c)\n",
    "print('MSE of test:', mean_squared_error(Y_train_ADR, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.125    ,  79.25     ,  71.1171875, ..., 149.1015625,\n",
       "        95.0546875, 155.390625 ])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_pred = reg.predict(X_test_c )\n",
    "reg_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1104.5432258944538, 1104.537758679981, 1104.5148252807583, 1104.4253885796074, 1104.3498583311318, 1104.2556302876558, 1104.1262643862037, 1108.1575447599566, 1165.0901382645745]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "Accuracy = []\n",
    "regularization = [0.001, 0.01, 0.05, 0.25, 0.5, 1, 10, 100, 1000]\n",
    "for c in regularization:\n",
    "    E_val_mse = []\n",
    "    for i in range(5):\n",
    "        lridge = Ridge(alpha =c)\n",
    "        lridge.fit(Tra_5folds_X[i] , Tra_5folds_ADR[i])\n",
    "        E_val_mse.append(mean_squared_error(Val_5folds_ADR[i], lridge.predict(Val_5folds_X[i])))\n",
    "    Accuracy.append(np.mean(E_val_mse))  \n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest C: 10\n",
      "Min MSE: 1104.1262643862037\n",
      "Train Acc: 1097.6137835402112\n"
     ]
    }
   ],
   "source": [
    "bestC = [regularization[i] for i in range(len(regularization)) if Accuracy[i] ==min(Accuracy)][0]\n",
    "print('highest C:',bestC)\n",
    "print('Min MSE:',min(Accuracy))\n",
    "\n",
    "lridge_model = Ridge(alpha = bestC )\n",
    "lridge_model.fit(X_train_c, Y_train_ADR)\n",
    "print(f'Train Acc: {mean_squared_error(Y_train_ADR, lridge_model.predict(X_train_c))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101.06923055,  80.25408028,  71.91809973, ..., 148.22254823,\n",
       "        94.23839143, 153.09713845])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lridge_pred = lridge_model.predict(X_test_c)\n",
    "lridge_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 382.8109145628419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "NNreg_model = MLPRegressor(random_state=1, hidden_layer_sizes=200)\n",
    "NNreg_model.fit(X_train_c, Y_train_ADR)\n",
    "y_pred = NNreg_model.predict(X_train_c)\n",
    "print(f'Test MSE: {mean_squared_error(Y_train_ADR, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103.50209291,  80.69683205,  84.10910136, ..., 207.99900711,\n",
       "        88.38148714, 128.92922495])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_NNreg_pred = NNreg_model.predict(X_test_c)\n",
    "real_NNreg_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 684.733587393979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbreg = GradientBoostingRegressor(random_state=0,max_depth=5)\n",
    "gbreg.fit(x_train, y_train)\n",
    "y_pred = gbreg.predict(x_test)\n",
    "print(f'Test MSE: {mean_squared_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 88.36772984,  64.22226255,  50.12183555, ..., 205.18923498,\n",
       "        98.91291725, 116.07145615])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbreg_pred = gbreg.predict(X_test_c)\n",
    "gbreg_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1858.8954721972934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "adareg = AdaBoostRegressor(random_state=0, n_estimators=200)\n",
    "adareg.fit(x_train, y_train)\n",
    "y_pred = adareg.predict(x_test)\n",
    "print(f'Test MSE: {mean_squared_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103.93772325,  98.5873158 ,  79.6147115 , ..., 148.92589746,\n",
       "       126.25936467, 122.95984582])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adareg_pred = adareg.predict(X_test_c)\n",
    "adareg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train label accuracy\n",
    "def Tr_Daily_Revenue(Test_Data,Test_label, cancel_prediction, adr_prediction):\n",
    "    Test_Data = Test_Data.copy() \n",
    "    Test_Data['adr']= adr_prediction\n",
    "    Test_Data['is_canceled'] = cancel_prediction\n",
    "    \n",
    "    Test_Data['arrival_date_month'] = pd.to_datetime(Test_Data.arrival_date_month, format='%B').dt.month\n",
    "    Test_Data['dateInt']=Test_Data['arrival_date_year'].astype(str)+Test_Data['arrival_date_month'].astype(str).str.zfill(2)+ Test_Data['arrival_date_day_of_month'].astype(str).str.zfill(2)\n",
    "            \n",
    "    Test_Data['arrive_Date'] = pd.to_datetime(Test_Data['dateInt'], format='%Y-%m-%d')\n",
    "    Test_Data['total_stay'] = Test_Data['stays_in_weekend_nights'] + Test_Data['stays_in_week_nights']\n",
    "    Target = Test_Data.loc[Test_Data['is_canceled'] ==0]\n",
    "    \n",
    "    Pre = []\n",
    "    D = Test_label['arrival_date']\n",
    "    for i in range(len(D)):\n",
    "        Ju = Target.loc[Target['arrive_Date']==D[i]]\n",
    "        Q = math.floor((np.dot(Ju['total_stay'].values,Ju['adr'].values))/10000)\n",
    "        Pre.append(Q)\n",
    "        \n",
    "    return Pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test label \n",
    "def Daily_Revenue(Test_Data,Test_label, cancel_prediction, adr_prediction):\n",
    "    Test_Data = Test_Data.copy() \n",
    "    Test_Data['adr']= adr_prediction\n",
    "    Test_Data['is_canceled'] = cancel_prediction\n",
    "    \n",
    "    Test_Data['arrival_date_month'] = pd.to_datetime(Test_Data.arrival_date_month, format='%B').dt.month\n",
    "    Test_Data['dateInt']=Test_Data['arrival_date_year'].astype(str)+Test_Data['arrival_date_month'].astype(str).str.zfill(2)+ Test_Data['arrival_date_day_of_month'].astype(str).str.zfill(2)\n",
    "            \n",
    "    Test_Data['arrive_Date'] = pd.to_datetime(Test_Data['dateInt'], format='%Y-%m-%d')\n",
    "    Test_Data['total_stay'] = Test_Data['stays_in_weekend_nights'] + Test_Data['stays_in_week_nights']\n",
    "    Target = Test_Data.loc[Test_Data['is_canceled'] ==0]\n",
    "    \n",
    "    Pre = []\n",
    "    D = Test_label['arrival_date']\n",
    "    for i in range(len(D)):\n",
    "        Ju = Target.loc[Target['arrive_Date']==D[i]]\n",
    "        Q = math.floor((np.dot(Ju['total_stay'].values,Ju['adr'].values))/10000)\n",
    "        Pre.append(Q)\n",
    "        \n",
    "    return Pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 74  20   0   0   0   0   0   0   0   0]\n",
      " [  7 102  41   2   0   0   0   0   0   0]\n",
      " [  0   9 125  46   6   0   0   0   0   0]\n",
      " [  0   0   4  78  38   4   0   0   0   0]\n",
      " [  0   0   0   7  27  10   2   0   0   0]\n",
      " [  0   0   0   0   8   9   4   0   0   0]\n",
      " [  0   0   0   0   1   4   8   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   2   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0]]\n",
      "0.6609375\n",
      "0.3671875\n"
     ]
    }
   ],
   "source": [
    "# Logistic + Ridge Reg\n",
    "from sklearn.metrics import confusion_matrix\n",
    "lab_pred = Tr_Daily_Revenue(X_train, Y_train, final_model.predict(X_train_c), lridge_model.predict(X_train_c))\n",
    "print(confusion_matrix(Y_train['label'], lab_pred))\n",
    "print(accuracy_score(Y_train['label'], lab_pred))\n",
    "print(mean_absolute_error(Y_train['label'], lab_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "import math \n",
    "DR = Daily_Revenue(X_test,Y_test, y_pred_log, lridge_pred)\n",
    "Test_label['label'] = DR\n",
    "Test_label.to_csv(r'C:\\Users\\USER\\Desktop\\UB.csv',index=False)\n",
    "print(np.array(DR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test_pred_label =  pd.DataFrame() \n",
    "Test_pred_label['arrival_date'] = Y_test['arrival_date']\n",
    "Test_pred_label['log&rid'] = DR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 76  18   0   0   0   0   0   0   0   0]\n",
      " [  9 107  35   1   0   0   0   0   0   0]\n",
      " [  0  20 125  38   3   0   0   0   0   0]\n",
      " [  0   0  12  84  24   4   0   0   0   0]\n",
      " [  0   0   0   8  28   7   3   0   0   0]\n",
      " [  0   0   0   1   8   8   4   0   0   0]\n",
      " [  0   0   0   0   1   4   6   2   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   1]\n",
      " [  0   0   0   0   0   0   1   0   0   0]]\n",
      "0.6796875\n",
      "0.34375\n"
     ]
    }
   ],
   "source": [
    "# Decision + Ridge\n",
    "lab_pred = Tr_Daily_Revenue(X_train, Y_train, final_model.predict(X_train_c), lridge_model.predict(X_train_c))\n",
    "print(confusion_matrix(Y_train['label'], lab_pred))\n",
    "print(accuracy_score(Y_train['label'], lab_pred))\n",
    "print(mean_absolute_error(Y_train['label'], lab_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 3, 1, 2, 2, 2, 3, 6, 5, 3, 3, 6, 4, 4, 3, 3, 1, 2, 2, 3, 3, 4, 3, 2, 1, 3, 5, 7, 3, 5, 4, 3, 4, 4, 4, 3, 4, 3, 2, 3, 2, 3, 3, 3, 2, 2, 3, 2, 2, 4, 3, 2, 4, 7, 4, 3, 5, 4, 3, 2, 4, 6, 5, 4, 5, 2, 2, 3, 3, 3, 4, 3, 2, 2, 4, 2, 3, 5, 5, 3, 3, 3, 4, 5, 4, 5, 3, 3, 4, 4, 5, 3, 5, 3, 2, 3, 3, 3, 5, 5, 4, 3, 3, 3, 6, 5, 6, 3, 2, 3, 3, 4, 4, 6, 4, 4, 4, 4, 6, 5, 5, 3, 4, 4, 3, 4, 4, 7, 3, 3, 4, 3, 5, 4, 4, 3, 4, 4, 4, 4, 5, 4, 2, 4, 4, 4, 5, 4, 4, 3, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_pred = Daily_Revenue(X_test, Y_test, y_pred_dt, lridge_pred)\n",
    "Test_pred_label['dt&rid'] = test_pred\n",
    "\n",
    "Test_label['label'] = test_pred\n",
    "Test_label.to_csv(r'C:\\Users\\USER\\Desktop\\UB.csv',index=False)\n",
    "#Test_label.to_csv(r'C:\\Users\\USER\\Desktop\\Test_record.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 90   4   0   0   0   0   0   0   0   0]\n",
      " [  9 126  17   0   0   0   0   0   0   0]\n",
      " [  0  23 144  19   0   0   0   0   0   0]\n",
      " [  0   0  14  95  15   0   0   0   0   0]\n",
      " [  0   0   0  11  31   4   0   0   0   0]\n",
      " [  0   0   0   2  10   9   0   0   0   0]\n",
      " [  0   0   0   0   2   4   7   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0]]\n",
      "0.7859375\n",
      "0.2234375\n"
     ]
    }
   ],
   "source": [
    "# RF + Ridge\n",
    "lab_pred = Tr_Daily_Revenue(X_train, Y_train, md1_rf.predict(X_train_c), lridge_model.predict(X_train_c))\n",
    "print(confusion_matrix(Y_train['label'], lab_pred))\n",
    "print(accuracy_score(Y_train['label'], lab_pred))\n",
    "print(mean_absolute_error(Y_train['label'], lab_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 4, 1, 2, 2, 2, 4, 5, 4, 3, 2, 6, 4, 4, 4, 4, 2, 3, 2, 3, 4, 4, 3, 2, 1, 3, 7, 6, 4, 5, 4, 3, 4, 5, 5, 4, 5, 3, 2, 3, 3, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 3, 5, 7, 4, 4, 6, 4, 3, 3, 5, 6, 6, 5, 6, 3, 2, 5, 4, 4, 6, 4, 3, 3, 5, 4, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 3, 3, 3, 4, 7, 4, 6, 4, 3, 4, 4, 5, 6, 6, 4, 3, 4, 3, 8, 6, 8, 4, 3, 4, 4, 6, 6, 8, 5, 4, 5, 5, 8, 5, 7, 6, 6, 7, 6, 6, 6, 10, 4, 5, 5, 4, 8, 7, 7, 6, 7, 7, 6, 7, 8, 6, 4, 5, 5, 5, 7, 6, 10, 4, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_pred = Daily_Revenue(X_test, Y_test, y_pred_rf, lridge_pred)\n",
    "Test_pred_label['rf&rid'] = test_pred\n",
    "\n",
    "Test_label['label'] = test_pred\n",
    "Test_label.to_csv(r'C:\\Users\\USER\\Desktop\\UB.csv',index=False)\n",
    "print(test_pred)\n",
    "Test_pred_label.to_csv(r'C:\\Users\\USER\\Desktop\\Test_record.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 84  10   0   0   0   0   0   0   0   0]\n",
      " [  6 120  25   1   0   0   0   0   0   0]\n",
      " [  0  18 140  28   0   0   0   0   0   0]\n",
      " [  0   0  10  95  18   1   0   0   0   0]\n",
      " [  0   0   0  10  29   7   0   0   0   0]\n",
      " [  0   0   0   1   8  10   2   0   0   0]\n",
      " [  0   0   0   0   2   2   9   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0]]\n",
      "0.7640625\n",
      "0.246875\n"
     ]
    }
   ],
   "source": [
    "# GB + ridge\n",
    "lab_pred = Tr_Daily_Revenue(X_train, Y_train, gb_model.predict(X_train_c), lridge_model.predict(X_train_c))\n",
    "print(confusion_matrix(Y_train['label'], lab_pred))\n",
    "print(accuracy_score(Y_train['label'], lab_pred))\n",
    "print(mean_absolute_error(Y_train['label'], lab_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 4, 1, 2, 2, 2, 4, 5, 4, 3, 2, 5, 4, 3, 4, 4, 2, 3, 2, 3, 4, 4, 3, 2, 1, 3, 6, 6, 4, 5, 4, 3, 4, 5, 5, 3, 4, 3, 2, 3, 3, 4, 4, 3, 3, 3, 4, 3, 3, 4, 4, 3, 5, 7, 4, 3, 5, 4, 3, 3, 5, 6, 6, 4, 6, 2, 2, 5, 3, 4, 6, 4, 3, 3, 5, 4, 5, 5, 5, 3, 4, 4, 4, 5, 5, 5, 3, 3, 3, 4, 6, 3, 6, 4, 3, 3, 3, 4, 6, 5, 4, 3, 3, 3, 7, 6, 7, 4, 3, 3, 4, 5, 6, 7, 4, 4, 5, 4, 7, 5, 6, 5, 5, 7, 5, 6, 6, 9, 4, 4, 5, 4, 7, 7, 6, 5, 6, 6, 6, 6, 7, 5, 3, 5, 5, 5, 6, 5, 9, 4, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_pred = Daily_Revenue(X_test, Y_test, gb_pred, lridge_pred)\n",
    "Test_pred_label['gb&rid'] = test_pred\n",
    "\n",
    "Test_label['label'] = test_pred\n",
    "Test_label.to_csv(r'C:\\Users\\USER\\Desktop\\UB.csv',index=False)\n",
    "print(test_pred)\n",
    "Test_pred_label.to_csv(r'C:\\Users\\USER\\Desktop\\Test_record.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 79  15   0   0   0   0   0   0   0   0   0]\n",
      " [  1 108  42   0   1   0   0   0   0   0   0]\n",
      " [  0   1 135  47   3   0   0   0   0   0   0]\n",
      " [  0   0   2  74  47   1   0   0   0   0   0]\n",
      " [  0   0   0   2  29  12   3   0   0   0   0]\n",
      " [  0   0   0   0   4   7   9   1   0   0   0]\n",
      " [  0   0   0   0   0   4   5   4   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0]]\n",
      "0.684375\n",
      "0.3328125\n"
     ]
    }
   ],
   "source": [
    "# Logis + NN\n",
    "lab_pred = Tr_Daily_Revenue(X_train, Y_train, final_model.predict(X_train_c), NNreg_model.predict(X_train_c))\n",
    "print(confusion_matrix(Y_train['label'], lab_pred))\n",
    "print(accuracy_score(Y_train['label'], lab_pred))\n",
    "print(mean_absolute_error(Y_train['label'], lab_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 3, 1, 2, 2, 2, 3, 5, 4, 3, 3, 5, 4, 4, 3, 3, 1, 2, 2, 3, 3, 4, 3, 2, 1, 3, 6, 6, 3, 4, 3, 2, 3, 4, 4, 3, 4, 2, 1, 3, 2, 3, 3, 3, 2, 2, 3, 2, 2, 4, 3, 2, 4, 5, 3, 2, 5, 3, 2, 2, 4, 6, 4, 4, 5, 2, 2, 4, 3, 3, 4, 4, 2, 2, 4, 3, 3, 5, 5, 3, 4, 4, 3, 5, 5, 4, 3, 3, 4, 4, 6, 3, 5, 4, 3, 4, 3, 4, 5, 5, 4, 3, 4, 4, 7, 5, 7, 5, 2, 4, 4, 4, 5, 6, 4, 4, 4, 4, 6, 5, 5, 4, 4, 5, 4, 5, 4, 8, 3, 3, 4, 5, 6, 4, 5, 3, 4, 5, 4, 4, 6, 6, 3, 5, 5, 4, 5, 4, 5, 3, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_pred = Daily_Revenue(X_test, Y_test, y_pred_log , real_NNreg_pred )\n",
    "Test_pred_label['log&NN'] = test_pred\n",
    "\n",
    "Test_label['label'] = test_pred\n",
    "Test_label.to_csv(r'C:\\Users\\USER\\Desktop\\UB.csv',index=False)\n",
    "print(test_pred)\n",
    "Test_pred_label.to_csv(r'C:\\Users\\USER\\Desktop\\Test_record.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 78  16   0   0   0   0   0   0   0   0   0]\n",
      " [  4 116  32   0   0   0   0   0   0   0   0]\n",
      " [  0   5 141  40   0   0   0   0   0   0   0]\n",
      " [  0   0   2  82  38   2   0   0   0   0   0]\n",
      " [  0   0   0   3  31  12   0   0   0   0   0]\n",
      " [  0   0   0   0   3  10   8   0   0   0   0]\n",
      " [  0   0   0   0   0   3   6   3   1   0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0]]\n",
      "0.728125\n",
      "0.278125\n"
     ]
    }
   ],
   "source": [
    "# Dec + NN\n",
    "lab_pred = Tr_Daily_Revenue(X_train, Y_train, final_model.predict(X_train_c), NNreg_model.predict(X_train_c))\n",
    "print(confusion_matrix(Y_train['label'], lab_pred))\n",
    "print(accuracy_score(Y_train['label'], lab_pred))\n",
    "print(mean_absolute_error(Y_train['label'], lab_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 3, 1, 2, 2, 2, 4, 4, 3, 3, 2, 4, 4, 3, 3, 4, 1, 2, 2, 4, 3, 4, 3, 2, 1, 3, 6, 5, 3, 5, 3, 2, 3, 4, 5, 4, 4, 2, 2, 3, 3, 4, 3, 3, 2, 2, 3, 3, 3, 4, 4, 2, 5, 5, 3, 2, 5, 3, 2, 2, 5, 5, 5, 4, 5, 2, 2, 5, 3, 4, 7, 5, 3, 3, 6, 4, 5, 5, 5, 3, 4, 5, 4, 6, 5, 4, 3, 3, 3, 4, 8, 4, 6, 5, 3, 5, 4, 4, 6, 6, 5, 3, 5, 4, 9, 6, 8, 5, 3, 4, 5, 6, 7, 8, 4, 4, 5, 5, 7, 5, 6, 6, 5, 7, 7, 7, 7, 10, 4, 4, 5, 5, 8, 8, 7, 4, 6, 9, 6, 6, 8, 7, 4, 6, 6, 5, 7, 6, 9, 3, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_pred = Daily_Revenue(X_test, Y_test, y_pred_dt , real_NNreg_pred )\n",
    "Test_pred_label['dt&NN'] = test_pred\n",
    "\n",
    "Test_label['label'] = test_pred\n",
    "Test_label.to_csv(r'C:\\Users\\USER\\Desktop\\UB.csv',index=False)\n",
    "print(test_pred)\n",
    "Test_pred_label.to_csv(r'C:\\Users\\USER\\Desktop\\Test_record.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 90   4   0   0   0   0   0   0   0   0]\n",
      " [  0 140  12   0   0   0   0   0   0   0]\n",
      " [  0   2 172  12   0   0   0   0   0   0]\n",
      " [  0   0   5 110   9   0   0   0   0   0]\n",
      " [  0   0   0   1  41   4   0   0   0   0]\n",
      " [  0   0   0   0   2  15   4   0   0   0]\n",
      " [  0   0   0   0   0   2   9   2   0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1]]\n",
      "0.9078125\n",
      "0.0921875\n"
     ]
    }
   ],
   "source": [
    "# RF + NN\n",
    "lab_pred = Tr_Daily_Revenue(X_train, Y_train, md1_rf.predict(X_train_c),  NNreg_model.predict(X_train_c) )\n",
    "print(confusion_matrix(Y_train['label'], lab_pred))\n",
    "print(accuracy_score(Y_train['label'], lab_pred))\n",
    "print(mean_absolute_error(Y_train['label'], lab_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 4, 1, 3, 2, 2, 4, 4, 3, 3, 2, 5, 4, 4, 4, 3, 2, 2, 2, 4, 4, 4, 4, 2, 1, 3, 7, 5, 3, 5, 4, 3, 3, 5, 5, 4, 5, 2, 2, 3, 3, 4, 4, 3, 2, 2, 3, 3, 3, 4, 4, 3, 5, 6, 3, 3, 6, 3, 2, 2, 5, 5, 5, 4, 5, 3, 3, 5, 4, 5, 7, 5, 3, 4, 6, 5, 6, 6, 6, 4, 4, 5, 4, 5, 5, 5, 3, 3, 3, 4, 8, 5, 6, 6, 4, 5, 5, 5, 6, 6, 5, 3, 5, 4, 9, 7, 9, 5, 3, 4, 5, 6, 7, 9, 5, 4, 5, 6, 8, 5, 7, 7, 6, 8, 7, 7, 7, 11, 5, 5, 6, 5, 9, 8, 8, 6, 8, 9, 7, 8, 8, 8, 5, 6, 6, 6, 8, 6, 10, 4, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_pred = Daily_Revenue(X_test, Y_test, y_pred_rf , real_NNreg_pred )\n",
    "Test_pred_label['rf&NN'] = test_pred\n",
    "\n",
    "Test_label['label'] = test_pred\n",
    "Test_label.to_csv(r'C:\\Users\\USER\\Desktop\\UB.csv',index=False)\n",
    "print(test_pred)\n",
    "Test_pred_label.to_csv(r'C:\\Users\\USER\\Desktop\\Test_record.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 84  10   0   0   0   0   0   0   0   0   0]\n",
      " [  3 125  24   0   0   0   0   0   0   0   0]\n",
      " [  0   5 157  24   0   0   0   0   0   0   0]\n",
      " [  0   0   4  97  23   0   0   0   0   0   0]\n",
      " [  0   0   0   3  36   7   0   0   0   0   0]\n",
      " [  0   0   0   0   4  12   4   1   0   0   0]\n",
      " [  0   0   0   0   0   1   9   3   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0]]\n",
      "0.8140625\n",
      "0.1875\n"
     ]
    }
   ],
   "source": [
    "# GB+NN\n",
    "lab_pred = Tr_Daily_Revenue(X_train, Y_train,  gb_model.predict(X_train_c),  NNreg_model.predict(X_train_c) )\n",
    "print(confusion_matrix(Y_train['label'], lab_pred))\n",
    "print(accuracy_score(Y_train['label'], lab_pred))\n",
    "print(mean_absolute_error(Y_train['label'], lab_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 3, 1, 3, 2, 2, 4, 4, 3, 3, 2, 4, 3, 3, 4, 3, 2, 3, 2, 4, 3, 4, 3, 2, 1, 3, 6, 5, 3, 5, 3, 2, 3, 4, 5, 3, 4, 2, 2, 3, 3, 4, 4, 3, 2, 2, 4, 3, 3, 4, 4, 3, 5, 5, 3, 3, 5, 3, 2, 2, 5, 5, 5, 4, 5, 2, 2, 5, 3, 4, 7, 5, 3, 3, 6, 4, 5, 5, 5, 4, 4, 4, 4, 4, 5, 4, 3, 3, 3, 4, 7, 4, 6, 5, 3, 4, 3, 4, 6, 6, 5, 3, 5, 4, 8, 7, 8, 5, 3, 4, 5, 6, 6, 8, 4, 4, 5, 5, 7, 5, 6, 6, 5, 7, 6, 7, 7, 10, 4, 5, 5, 5, 8, 7, 7, 5, 7, 7, 7, 6, 7, 7, 4, 5, 6, 5, 7, 6, 9, 4, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_pred = Daily_Revenue(X_test, Y_test, gb_pred , real_NNreg_pred )\n",
    "Test_pred_label['gb&NN'] = test_pred\n",
    "\n",
    "Test_label['label'] = test_pred\n",
    "Test_label.to_csv(r'C:\\Users\\USER\\Desktop\\UB.csv',index=False)\n",
    "print(test_pred)\n",
    "Test_pred_label.to_csv(r'C:\\Users\\USER\\Desktop\\Test_record.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153, 8)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_pred_label.iloc[:,1:].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 3, 2, 3]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Test_pred_label.iloc[:,1:].to_numpy()[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 3, 1, 2, 2, 2, 4, 4, 4, 3, 2, 5, 4, 3, 4, 3, 1, 2, 2, 3, 3, 4, 3, 2, 1, 3, 6, 6, 3, 5, 3, 3, 3, 4, 5, 3, 4, 2, 2, 3, 3, 4, 4, 3, 2, 2, 3, 3, 3, 4, 4, 2, 5, 7, 3, 3, 5, 3, 2, 2, 5, 5, 5, 4, 5, 2, 2, 5, 3, 4, 6, 4, 3, 3, 5, 4, 5, 5, 5, 3, 4, 4, 4, 5, 5, 4, 3, 3, 3, 4, 7, 4, 6, 4, 3, 4, 3, 4, 6, 5, 4, 3, 3, 3, 8, 6, 8, 5, 3, 4, 4, 6, 6, 8, 4, 4, 5, 4, 7, 5, 6, 6, 5, 7, 5, 6, 6, 10, 4, 3, 5, 5, 8, 7, 7, 3, 6, 6, 6, 6, 8, 6, 3, 5, 5, 5, 7, 6, 9, 3, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "def most_frequent(List): \n",
    "    return max(set(List), key = List.count) \n",
    "  \n",
    "UB = [most_frequent(list(Test_pred_label.iloc[:,1:].to_numpy()[i])) for i in range(153)]\n",
    "print(UB)\n",
    "\n",
    "Test_label['label'] = UB\n",
    "Test_label.to_csv(r'C:\\Users\\USER\\Desktop\\UB.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
